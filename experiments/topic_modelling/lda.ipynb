{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import jieba.posseg as jp, jieba\n",
    "from load_document import load_documents, get_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[使用LDA进行文档主题建模](https://github.com/duoergun0729/nlp/blob/master/%E4%BD%BF%E7%94%A8LDA%E8%BF%9B%E8%A1%8C%E6%96%87%E6%A1%A3%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1.md)\n",
    "\n",
    "[Python+gensim【中文LDA】](https://blog.csdn.net/Yellow_python/article/details/83097994)\n",
    "\n",
    "[scikit-learn LDA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = \"/home/junetheriver/codes/qa_generation/huawei/data/UNC_20.9.5\"\n",
    "files = load_documents(demo_path)\n",
    "files = get_content(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['html', 'cn', 'Document', 'zh', 'png', 'G']\n",
    "\n",
    "stopwords_file = \"/home/junetheriver/codes/qa_generation/huawei/data/stopwords/all_stopwords.txt\"\n",
    "with open(stopwords_file, 'r') as f:\n",
    "    for line in f:\n",
    "        stop_words.append(line.strip())\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "words_ls = []\n",
    "metadata_ls = []\n",
    "flags = ('n', 'nr', 'ns', 'nt', 'eng', 'v', 'd')\n",
    "# noun, proper noun for a person's name, proper noun for a place, proper noun for a organization, English word, verb, adverb\n",
    "\n",
    "for file in files:\n",
    "    words = [w.word for w in jp.cut(file['content']) if w.flag in flags and w.word not in stop_words]\n",
    "    words_ls.append(words)\n",
    "    metadata_ls.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('words_ls.pkl', 'wb') as f:\n",
    "    pkl.dump(words_ls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到文档-单词矩阵 （直接利用统计词频得到特征）\n",
    "dictionary = corpora.Dictionary(words_ls)\n",
    "# 将dictionary转化为一个词袋，得到文档-单词矩阵\n",
    "corpus = [dictionary.doc2bow(words) for words in words_ls]\n",
    "# 词袋处理后的结果，使用TF-IDF算法处理后，可以进一步提升LDA的效果\n",
    "texts_tf_idf = models.TfidfModel(corpus)[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.011*\"统计\" + 0.010*\"性能\" + 0.009*\"预留\" + 0.006*\"承载\" + 0.006*\"采集\" + 0.005*\"参数\" + 0.005*\"计算公式\" + 0.005*\"测量点\" + 0.005*\"相关\" + 0.005*\"单位\" + 0.005*\"消息\" + 0.005*\"APN\" + 0.005*\"次数\" + 0.004*\"说明书\" + 0.004*\"指标\" + 0.004*\"MME\" + 0.004*\"数\" + 0.004*\"失败\" + 0.004*\"指定\" + 0.003*\"SGW\"')\n",
      "(1, '0.006*\"参数\" + 0.005*\"统计\" + 0.004*\"消息\" + 0.003*\"数\" + 0.003*\"SMF\" + 0.003*\"信元\" + 0.003*\"接收\" + 0.003*\"采集\" + 0.003*\"命令\" + 0.003*\"测量点\" + 0.003*\"计算公式\" + 0.003*\"接口\" + 0.003*\"MME\" + 0.003*\"发送\" + 0.003*\"次数\" + 0.003*\"单位\" + 0.003*\"PDU\" + 0.003*\"相关\" + 0.003*\"UPF\" + 0.003*\"指标\"')\n",
      "(2, '0.015*\"性能\" + 0.013*\"预留\" + 0.011*\"统计\" + 0.007*\"说明书\" + 0.006*\"参数\" + 0.006*\"采集\" + 0.005*\"项\" + 0.005*\"计算公式\" + 0.005*\"测量点\" + 0.005*\"参考\" + 0.005*\"相关\" + 0.005*\"单位\" + 0.004*\"指标\" + 0.004*\"命令\" + 0.004*\"次数\" + 0.003*\"消息\" + 0.003*\"指定\" + 0.003*\"版本\" + 0.003*\"UE\" + 0.003*\"取\"')\n",
      "(3, '0.006*\"统计\" + 0.006*\"参数\" + 0.004*\"消息\" + 0.004*\"次数\" + 0.004*\"测量点\" + 0.004*\"计算公式\" + 0.004*\"采集\" + 0.003*\"单位\" + 0.003*\"命令\" + 0.003*\"请求\" + 0.003*\"发送\" + 0.003*\"相关\" + 0.003*\"附着\" + 0.003*\"指标\" + 0.003*\"指定\" + 0.003*\"SMF\" + 0.003*\"数\" + 0.003*\"Session\" + 0.003*\"接口\" + 0.003*\"MME\"')\n",
      "(4, '0.006*\"参数\" + 0.005*\"统计\" + 0.004*\"消息\" + 0.004*\"命令\" + 0.003*\"采集\" + 0.003*\"相关\" + 0.003*\"接口\" + 0.003*\"测量点\" + 0.003*\"计算公式\" + 0.003*\"发送\" + 0.003*\"PGW\" + 0.003*\"数\" + 0.003*\"次数\" + 0.003*\"单位\" + 0.003*\"更新\" + 0.003*\"指定\" + 0.003*\"指标\" + 0.003*\"用户\" + 0.003*\"MME\" + 0.003*\"配置\"')\n",
      "(5, '0.008*\"统计\" + 0.005*\"承载\" + 0.005*\"参数\" + 0.005*\"次数\" + 0.005*\"附着\" + 0.005*\"测量点\" + 0.005*\"计算公式\" + 0.005*\"采集\" + 0.005*\"消息\" + 0.004*\"单位\" + 0.004*\"失败\" + 0.004*\"性能\" + 0.004*\"相关\" + 0.004*\"指标\" + 0.004*\"PGW\" + 0.004*\"发送\" + 0.004*\"预留\" + 0.004*\"SGSN\" + 0.004*\"SGW\" + 0.004*\"指定\"')\n",
      "(6, '0.007*\"参数\" + 0.004*\"命令\" + 0.004*\"统计\" + 0.004*\"消息\" + 0.003*\"配置\" + 0.003*\"接口\" + 0.003*\"失败\" + 0.003*\"次数\" + 0.003*\"测量点\" + 0.003*\"计算公式\" + 0.003*\"用户\" + 0.003*\"发送\" + 0.003*\"单位\" + 0.003*\"信元\" + 0.003*\"必选\" + 0.003*\"接收\" + 0.003*\"参\" + 0.002*\"报文\" + 0.002*\"Response\" + 0.002*\"采集\"')\n",
      "(7, '0.005*\"参数\" + 0.004*\"统计\" + 0.004*\"MME\" + 0.003*\"命令\" + 0.003*\"消息\" + 0.003*\"次数\" + 0.003*\"告警\" + 0.003*\"UE\" + 0.003*\"计算公式\" + 0.003*\"测量点\" + 0.003*\"模式\" + 0.003*\"单位\" + 0.003*\"用户\" + 0.003*\"TAU\" + 0.002*\"发送\" + 0.002*\"参\" + 0.002*\"SGSN\" + 0.002*\"指标\" + 0.002*\"失败\" + 0.002*\"TS\"')\n",
      "(8, '0.006*\"参数\" + 0.006*\"统计\" + 0.004*\"消息\" + 0.004*\"数\" + 0.004*\"采集\" + 0.004*\"SMF\" + 0.003*\"命令\" + 0.003*\"计算公式\" + 0.003*\"测量点\" + 0.003*\"指定\" + 0.003*\"APN\" + 0.003*\"相关\" + 0.003*\"单位\" + 0.003*\"PGW\" + 0.003*\"指标\" + 0.003*\"发送\" + 0.003*\"PDU\" + 0.003*\"次数\" + 0.003*\"接收\" + 0.003*\"接口\"')\n",
      "(9, '0.008*\"参数\" + 0.006*\"统计\" + 0.005*\"性能\" + 0.005*\"命令\" + 0.004*\"预留\" + 0.004*\"采集\" + 0.004*\"消息\" + 0.003*\"测量点\" + 0.003*\"计算公式\" + 0.003*\"SGW\" + 0.003*\"相关\" + 0.003*\"配置\" + 0.003*\"单位\" + 0.003*\"必选\" + 0.003*\"次数\" + 0.003*\"数\" + 0.003*\"失败\" + 0.003*\"PGW\" + 0.003*\"指标\" + 0.003*\"接口\"')\n",
      "(array([[1.00020878e-01, 1.00038216e-01, 1.00025907e-01, ...,\n",
      "        4.51507072e+01, 1.00022919e-01, 1.00029171e-01],\n",
      "       [1.00024186e-01, 2.80147285e+01, 8.67664261e+01, ...,\n",
      "        1.00029595e-01, 1.00025661e-01, 1.00028813e-01],\n",
      "       [1.00020982e-01, 1.00025058e-01, 1.00024074e-01, ...,\n",
      "        6.24508438e+01, 1.00020811e-01, 1.00026272e-01],\n",
      "       ...,\n",
      "       [1.00019529e-01, 1.72198975e+02, 1.74732342e+01, ...,\n",
      "        5.45763435e+01, 1.00025617e-01, 9.88936081e+01],\n",
      "       [1.00021400e-01, 2.62382355e+01, 1.00027554e-01, ...,\n",
      "        3.93016891e+01, 1.00029603e-01, 6.90103226e+01],\n",
      "       [1.00019403e-01, 2.18198471e+02, 2.71148285e+02, ...,\n",
      "        1.00027733e-01, 1.00022793e-01, 6.88567276e+01]], dtype=float32), None)\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "lda = models.LdaMulticore(corpus=texts_tf_idf, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "for topic in lda.print_topics(num_words=20):\n",
    "    print(topic)\n",
    "\n",
    "print(lda.inference(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.046*\"消息\" + 0.031*\"UE\" + 0.023*\"流程\" + 0.017*\"发送\" + 0.017*\"MME\" + 0.017*\"Request\" + 0.016*\"承载\" + 0.014*\"PGW\" + 0.013*\"信元\" + 0.012*\"SMF\"')\n",
      "(1, '0.029*\"配置\" + 0.019*\"特性\" + 0.015*\"用户\" + 0.015*\"ADD\" + 0.013*\"计费\" + 0.012*\"MML\" + 0.011*\"时\" + 0.011*\"场景\" + 0.010*\"业务\" + 0.009*\"支持\"')\n",
      "(2, '0.030*\"用户\" + 0.026*\"网络\" + 0.022*\"MME\" + 0.017*\"SGSN\" + 0.014*\"路由\" + 0.012*\"模式\" + 0.010*\"G\" + 0.010*\"位置\" + 0.010*\"eNodeB\" + 0.009*\"业务\"')\n",
      "(3, '0.027*\"统计\" + 0.026*\"次数\" + 0.025*\"消息\" + 0.023*\"参考\" + 0.022*\"类型\" + 0.022*\"指标\" + 0.021*\"相关\" + 0.020*\"KPI\" + 0.017*\"单位\" + 0.017*\"计算公式\"')\n",
      "(4, '0.019*\"Document\" + 0.013*\"信息\" + 0.012*\"cn\" + 0.011*\"zh\" + 0.011*\"MML\" + 0.008*\"名称\" + 0.008*\"操作\" + 0.008*\"参数\" + 0.008*\"告警\" + 0.007*\"VNF\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_words=10, num_topics=10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn的LDA实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(words_ls)\n",
    "\n",
    "num_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
    "lda.fit(X)\n",
    "\n",
    "# 获取文档的主题分布\n",
    "doc_topic_dist = lda.transform(X)\n",
    "\n",
    "# 对于每个主题，找到在该主题上概率最高的文档\n",
    "n_top_docs = 2  # 每个主题最相关的2篇文档\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    print(f\"主题 {topic_idx}:\")\n",
    "    # 获取第 topic_idx 个主题的文档概率\n",
    "    topic_doc_probs = doc_topic_dist[:, topic_idx]\n",
    "    # 按概率降序排序，获取最高的文档索引\n",
    "    top_doc_indices = topic_doc_probs.argsort()[::-1][:n_top_docs]\n",
    "    for doc_idx in top_doc_indices:\n",
    "        print(f\"文档 {doc_idx}（概率 {topic_doc_probs[doc_idx]:.4f}）:\")\n",
    "        # print(f\"内容: {documents[doc_idx]}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencompass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
